"""
RabbitMQ äº‹ä»¶ç™¼é€å™¨
è² è²¬å°‡ç›£æ§äº‹ä»¶ç•°æ­¥ç™¼é€åˆ° RabbitMQ ä½‡åˆ—
"""

import asyncio
import json
import logging
from typing import Optional, Dict, Any
from datetime import datetime

import aio_pika
from aio_pika import Message, DeliveryMode, connect_robust
from aio_pika.abc import AbstractConnection, AbstractChannel, AbstractQueue

from .metrics_event import MetricsEvent, HealthEvent
from ..api.config import get_settings

logger = logging.getLogger(__name__)


class EventPublisher:
    """
    RabbitMQ äº‹ä»¶ç™¼é€å™¨
    
    è² è²¬ï¼š
    1. å»ºç«‹å’Œç®¡ç† RabbitMQ é€£æ¥
    2. ç•°æ­¥ç™¼é€ç›£æ§äº‹ä»¶
    3. å¯¦ç¾é‡è©¦æ©Ÿåˆ¶
    4. ç¢ºä¿äº‹ä»¶ç™¼é€ä¸å½±éŸ¿ä¸»è¦æ¥­å‹™é‚è¼¯
    """
    
    def __init__(self, rabbitmq_url: Optional[str] = None):
        """
        åˆå§‹åŒ–äº‹ä»¶ç™¼é€å™¨
        
        Args:
            rabbitmq_url: RabbitMQ é€£æ¥å­—ä¸²ï¼ŒNone æ™‚ä½¿ç”¨é…ç½®æ–‡ä»¶
        """
        self.settings = get_settings()
        self.rabbitmq_url = rabbitmq_url or self.settings.RABBITMQ_URL
        self.metrics_queue_name = self.settings.METRICS_QUEUE_NAME
        self.alerts_queue_name = self.settings.ALERTS_QUEUE_NAME
        
        self.connection: Optional[AbstractConnection] = None
        self.channel: Optional[AbstractChannel] = None
        self.metrics_queue: Optional[AbstractQueue] = None
        self.alerts_queue: Optional[AbstractQueue] = None
        
        self._is_connected = False
        self._connection_lock = asyncio.Lock()
    
    async def connect(self) -> bool:
        """
        å»ºç«‹ RabbitMQ é€£æ¥
        
        Returns:
            bool: é€£æ¥æ˜¯å¦æˆåŠŸ
        """
        async with self._connection_lock:
            if self._is_connected:
                return True
            
            try:
                logger.info(f"æ­£åœ¨é€£æ¥ RabbitMQ: {self.rabbitmq_url}")
                
                # å»ºç«‹é€£æ¥
                self.connection = await connect_robust(
                    self.rabbitmq_url,
                    heartbeat=60,  # å¿ƒè·³é–“éš”
                    blocked_connection_timeout=300,  # é˜»å¡é€£æ¥è¶…æ™‚
                )
                
                # å»ºç«‹é »é“
                self.channel = await self.connection.channel()
                await self.channel.set_qos(prefetch_count=1000)  # è¨­ç½® QoS
                
                # è²æ˜ä½‡åˆ—
                await self._declare_queues()
                
                self._is_connected = True
                logger.info("âœ… RabbitMQ é€£æ¥æˆåŠŸ")
                return True
                
            except Exception as e:
                logger.error(f"âŒ RabbitMQ é€£æ¥å¤±æ•—: {e}")
                self._is_connected = False
                return False
    
    async def _declare_queues(self):
        """è²æ˜æ‰€éœ€çš„ä½‡åˆ—"""
        # æŒ‡æ¨™äº‹ä»¶ä½‡åˆ—
        self.metrics_queue = await self.channel.declare_queue(
            self.metrics_queue_name,
            durable=True,  # æŒä¹…åŒ–ä½‡åˆ—
            arguments={
                "x-message-ttl": 86400000,  # è¨Šæ¯ TTL: 24 å°æ™‚
                "x-max-length": 100000,     # æœ€å¤§è¨Šæ¯æ•¸é‡
            }
        )
        
        # å‘Šè­¦äº‹ä»¶ä½‡åˆ—
        self.alerts_queue = await self.channel.declare_queue(
            self.alerts_queue_name,
            durable=True,
            arguments={
                "x-message-ttl": 604800000,  # è¨Šæ¯ TTL: 7 å¤©
                "x-max-length": 10000,       # æœ€å¤§è¨Šæ¯æ•¸é‡
            }
        )
        
        logger.info(f"âœ… ä½‡åˆ—è²æ˜å®Œæˆ: {self.metrics_queue_name}, {self.alerts_queue_name}")
    
    async def disconnect(self):
        """æ–·é–‹ RabbitMQ é€£æ¥"""
        async with self._connection_lock:
            if self.connection and not self.connection.is_closed:
                await self.connection.close()
                logger.info("RabbitMQ é€£æ¥å·²é—œé–‰")
            
            self._is_connected = False
            self.connection = None
            self.channel = None
            self.metrics_queue = None
            self.alerts_queue = None
    
    async def is_healthy(self) -> bool:
        """æª¢æŸ¥ç™¼é€å™¨å¥åº·ç‹€æ…‹"""
        return (
            self._is_connected and 
            self.connection and 
            not self.connection.is_closed and
            self.channel and
            not self.channel.is_closed
        )
    
    async def publish_metrics_event(
        self, 
        event: MetricsEvent, 
        max_retries: int = 3
    ) -> bool:
        """
        ç™¼é€æŒ‡æ¨™äº‹ä»¶
        
        Args:
            event: è¦ç™¼é€çš„æŒ‡æ¨™äº‹ä»¶
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            
        Returns:
            bool: ç™¼é€æ˜¯å¦æˆåŠŸ
        """
        if not await self.is_healthy():
            # å˜—è©¦é‡æ–°é€£æ¥
            if not await self.connect():
                logger.warning("RabbitMQ é€£æ¥å¤±æ•—ï¼Œäº‹ä»¶ç™¼é€è·³é")
                return False
        
        for attempt in range(max_retries + 1):
            try:
                # æº–å‚™è¨Šæ¯
                message_body = json.dumps(
                    event.to_rabbitmq_message(),
                    ensure_ascii=False,
                    separators=(',', ':')
                )
                
                message = Message(
                    message_body.encode('utf-8'),
                    delivery_mode=DeliveryMode.PERSISTENT,  # æŒä¹…åŒ–è¨Šæ¯
                    headers={
                        "event_type": event.event_type,
                        "service_name": event.service_name,
                        "timestamp": event.timestamp.isoformat(),
                        "attempt": attempt + 1
                    }
                )
                
                # ç™¼é€è¨Šæ¯
                await self.metrics_queue.channel.default_exchange.publish(
                    message,
                    routing_key=self.metrics_queue_name
                )
                
                logger.debug(
                    f"âœ… æŒ‡æ¨™äº‹ä»¶ç™¼é€æˆåŠŸ: {event.service_name}:{event.api_endpoint} "
                    f"(è€—æ™‚: {event.response_time_ms}ms)"
                )
                return True
                
            except Exception as e:
                logger.warning(
                    f"âš ï¸ æŒ‡æ¨™äº‹ä»¶ç™¼é€å¤±æ•— (å˜—è©¦ {attempt + 1}/{max_retries + 1}): {e}"
                )
                
                if attempt < max_retries:
                    # é‡è©¦å‰ç­‰å¾…
                    await asyncio.sleep(0.1 * (2 ** attempt))  # æŒ‡æ•¸é€€é¿
                    
                    # å˜—è©¦é‡æ–°é€£æ¥
                    if not await self.is_healthy():
                        await self.connect()
        
        logger.error(f"âŒ æŒ‡æ¨™äº‹ä»¶ç™¼é€å¾¹åº•å¤±æ•—: {event.event_id}")
        return False
    
    async def publish_health_event(
        self, 
        event: HealthEvent, 
        max_retries: int = 3
    ) -> bool:
        """
        ç™¼é€å¥åº·äº‹ä»¶
        
        Args:
            event: è¦ç™¼é€çš„å¥åº·äº‹ä»¶
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
            
        Returns:
            bool: ç™¼é€æ˜¯å¦æˆåŠŸ
        """
        if not await self.is_healthy():
            if not await self.connect():
                return False
        
        for attempt in range(max_retries + 1):
            try:
                message_body = json.dumps(
                    event.dict(),
                    ensure_ascii=False,
                    separators=(',', ':'),
                    default=str
                )
                
                message = Message(
                    message_body.encode('utf-8'),
                    delivery_mode=DeliveryMode.PERSISTENT,
                    headers={
                        "event_type": event.event_type,
                        "service_name": event.service_name,
                        "health_status": event.health_status,
                        "timestamp": event.timestamp.isoformat()
                    }
                )
                
                await self.alerts_queue.channel.default_exchange.publish(
                    message,
                    routing_key=self.alerts_queue_name
                )
                
                logger.debug(f"âœ… å¥åº·äº‹ä»¶ç™¼é€æˆåŠŸ: {event.service_name}")
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ å¥åº·äº‹ä»¶ç™¼é€å¤±æ•— (å˜—è©¦ {attempt + 1}): {e}")
                
                if attempt < max_retries:
                    await asyncio.sleep(0.1 * (2 ** attempt))
                    if not await self.is_healthy():
                        await self.connect()
        
        return False
    
    async def publish_batch_events(
        self, 
        events: list[MetricsEvent], 
        batch_size: int = 100
    ) -> int:
        """
        æ‰¹é‡ç™¼é€äº‹ä»¶
        
        Args:
            events: äº‹ä»¶åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            int: æˆåŠŸç™¼é€çš„äº‹ä»¶æ•¸é‡
        """
        if not events:
            return 0
        
        success_count = 0
        
        # åˆ†æ‰¹ç™¼é€
        for i in range(0, len(events), batch_size):
            batch = events[i:i + batch_size]
            batch_tasks = []
            
            for event in batch:
                task = asyncio.create_task(
                    self.publish_metrics_event(event, max_retries=1)
                )
                batch_tasks.append(task)
            
            # ç­‰å¾…æ‰¹æ¬¡å®Œæˆ
            results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            
            # çµ±è¨ˆæˆåŠŸæ•¸é‡
            for result in results:
                if isinstance(result, bool) and result:
                    success_count += 1
        
        logger.info(f"ğŸ“Š æ‰¹é‡ç™¼é€å®Œæˆ: {success_count}/{len(events)} äº‹ä»¶æˆåŠŸ")
        return success_count


# å…¨åŸŸäº‹ä»¶ç™¼é€å™¨å¯¦ä¾‹
_global_publisher: Optional[EventPublisher] = None


async def get_event_publisher() -> EventPublisher:
    """
    ç²å–å…¨åŸŸäº‹ä»¶ç™¼é€å™¨å¯¦ä¾‹
    
    Returns:
        EventPublisher: äº‹ä»¶ç™¼é€å™¨å¯¦ä¾‹
    """
    global _global_publisher
    
    if _global_publisher is None:
        _global_publisher = EventPublisher()
        await _global_publisher.connect()
    
    return _global_publisher


async def publish_metrics_event_async(event: MetricsEvent) -> bool:
    """
    ç•°æ­¥ç™¼é€æŒ‡æ¨™äº‹ä»¶çš„ä¾¿æ·å‡½æ•¸
    
    Args:
        event: æŒ‡æ¨™äº‹ä»¶
        
    Returns:
        bool: æ˜¯å¦ç™¼é€æˆåŠŸ
    """
    try:
        publisher = await get_event_publisher()
        return await publisher.publish_metrics_event(event)
    except Exception as e:
        logger.error(f"äº‹ä»¶ç™¼é€å¤±æ•—: {e}")
        return False 