"""
æ¸¬è©¦ç”¨ Model API æœå‹™
ç”¨æ–¼é©—è­‰ç›£æ§æ””æˆªå™¨çš„åŠŸèƒ½å’Œæ€§èƒ½
"""

import asyncio
import random
import time
from typing import Dict, Any, List, Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel, Field
import uvicorn

from src.components import add_monitoring_to_app
from src.api.config import get_settings

# å‰µå»ºæ¸¬è©¦ API æ‡‰ç”¨
app = FastAPI(
    title="æ¸¬è©¦ Model API",
    description="ç”¨æ–¼é©—è­‰ç›£æ§åŠŸèƒ½çš„æ¨¡æ“¬æ©Ÿå™¨å­¸ç¿’ API",
    version="1.0.0"
)

# æ·»åŠ ç›£æ§åŠŸèƒ½
monitor = add_monitoring_to_app(
    app, 
    service_name="test-model-api",
    config={
        "enable_detailed_logging": True,
        "exclude_paths": ["/health", "/docs", "/redoc", "/openapi.json"]
    }
)

# è«‹æ±‚/éŸ¿æ‡‰æ¨¡å‹
class PredictionRequest(BaseModel):
    """é æ¸¬è«‹æ±‚æ¨¡å‹"""
    features: List[float] = Field(..., description="ç‰¹å¾µå‘é‡(5å€‹æ•¸å€¼)", example=[0.5, 1.0, 0.8, 0.3, 0.7])
    metadata: Optional[Dict[str, Any]] = Field(default={}, description="å…ƒæ•¸æ“šä¿¡æ¯")
    model_version: Optional[str] = Field(default="v1.0", description="æ¨¡å‹ç‰ˆæœ¬")


class PredictionResponse(BaseModel):
    """é æ¸¬éŸ¿æ‡‰æ¨¡å‹"""
    predictions: List[float] = Field(..., description="é æ¸¬çµæœ")
    model_version: str = Field(..., description="ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬")
    processing_time_ms: float = Field(..., description="è™•ç†æ™‚é–“(æ¯«ç§’)")
    timestamp: str = Field(..., description="é æ¸¬æ™‚é–“")
    request_id: str = Field(..., description="è«‹æ±‚ID")


class ModelInfo(BaseModel):
    """æ¨¡å‹ä¿¡æ¯"""
    name: str
    version: str
    description: str
    input_features: int
    output_classes: int
    accuracy: float
    last_trained: str


class BatchPredictionRequest(BaseModel):
    """æ‰¹é‡é æ¸¬è«‹æ±‚"""
    samples: List[List[float]] = Field(..., description="æ¨£æœ¬åˆ—è¡¨")
    model_version: Optional[str] = Field(default="v1.0", description="æ¨¡å‹ç‰ˆæœ¬")


# æ¨¡æ“¬æ•¸æ“š
MOCK_MODELS = {
    "v1.0": ModelInfo(
        name="Linear Classifier",
        version="v1.0",
        description="ç°¡å–®ç·šæ€§åˆ†é¡æ¨¡å‹ - å¿«é€Ÿæ¨ç†",
        input_features=5,
        output_classes=2,
        accuracy=0.85,
        last_trained="2025-06-01T10:00:00Z"
    ),
    "v2.0": ModelInfo(
        name="Deep Neural Network", 
        version="v2.0",
        description="æ·±åº¦ç¥ç¶“ç¶²è·¯åˆ†é¡æ¨¡å‹ - é«˜ç²¾åº¦æ¨ç†",
        input_features=5,
        output_classes=2,
        accuracy=0.92,
        last_trained="2025-06-15T14:30:00Z"
    )
}


def simulate_model_inference(features: List[float], model_version: str = "v1.0", metadata: Dict[str, Any] = None) -> List[float]:
    """
    æ¨¡æ“¬æ¨¡å‹æ¨ç†éç¨‹
    
    Args:
        features: è¼¸å…¥ç‰¹å¾µ (5å€‹æ•¸å€¼)
        model_version: æ¨¡å‹ç‰ˆæœ¬
        metadata: å…ƒæ•¸æ“šä¿¡æ¯
        
    Returns:
        List[float]: é æ¸¬çµæœ [probability_class_0, probability_class_1]
    """
    # é©—è­‰ç‰¹å¾µå‘é‡
    if len(features) != 5:
        raise ValueError("ç‰¹å¾µå‘é‡å¿…é ˆåŒ…å« 5 å€‹å…ƒç´ ")
    
    # æ¨¡æ“¬ä¸åŒæ¨¡å‹çš„è™•ç†æ™‚é–“å’Œè¡Œç‚º
    if model_version == "v1.0":
        # ç°¡å–®æ¨¡å‹ï¼Œå¿«é€ŸéŸ¿æ‡‰ï¼Œè¼ƒä½æº–ç¢ºåº¦
        time.sleep(random.uniform(0.008, 0.025))  # 8-25ms
        weights = [0.15, 0.25, 0.20, 0.10, 0.30]  # ç°¡å–®æ¬Šé‡
        bias = 0.1
    elif model_version == "v2.0":
        # è¤‡é›œæ¨¡å‹ï¼Œè¼ƒæ…¢éŸ¿æ‡‰ï¼Œè¼ƒé«˜æº–ç¢ºåº¦
        time.sleep(random.uniform(0.040, 0.120))  # 40-120ms
        weights = [0.22, 0.18, 0.24, 0.16, 0.20]  # æ›´å¹³è¡¡çš„æ¬Šé‡
        bias = 0.05
    else:
        raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹ç‰ˆæœ¬: {model_version}")
    
    # æ ¹æ“šå…ƒæ•¸æ“šèª¿æ•´é æ¸¬è¡Œç‚º
    if metadata:
        feature_type = metadata.get("feature_type", "normal")
        
        # é‡å°ä¸åŒç‰¹å¾µé¡å‹æ¨¡æ“¬ä¸åŒçš„æ¨ç†çµæœ
        if feature_type == "error_prone":
            # å¢åŠ ä¸€äº›éš¨æ©Ÿæ€§ä»¥æ¨¡æ“¬ä¸ç©©å®šçš„é æ¸¬
            noise = random.uniform(-0.1, 0.1)
            bias += noise
        elif feature_type == "anomaly":
            # ç•°å¸¸ç‰¹å¾µå¯èƒ½å°è‡´æ¥µç«¯é æ¸¬
            if random.random() < 0.3:  # 30% æ©Ÿç‡ç”¢ç”Ÿæ¥µç«¯çµæœ
                return [random.choice([0.05, 0.95]), random.choice([0.05, 0.95])]
    
    # ç·šæ€§çµ„åˆè¨ˆç®—
    linear_combination = sum(f * w for f, w in zip(features, weights)) + bias
    
    # Sigmoid æ¿€æ´»å‡½æ•¸
    probability_class_1 = 1 / (1 + abs(linear_combination))
    probability_class_0 = 1 - probability_class_1
    
    # ç¢ºä¿æ¦‚ç‡å’Œç‚º1ä¸”åœ¨åˆç†ç¯„åœå…§
    total = probability_class_0 + probability_class_1
    probability_class_0 /= total
    probability_class_1 /= total
    
    return [round(probability_class_0, 4), round(probability_class_1, 4)]


@app.get("/", tags=["æ ¹ç›®éŒ„"])
async def root():
    """API æ ¹ç›®éŒ„"""
    return {
        "service": "Test Model API",
        "version": "1.0.0",
        "description": "ç”¨æ–¼é©—è­‰ç›£æ§åŠŸèƒ½çš„æ¨¡æ“¬æ©Ÿå™¨å­¸ç¿’ API",
        "endpoints": {
            "predict": "/predict",
            "batch_predict": "/batch_predict",
            "models": "/models",
            "health": "/health"
        }
    }


@app.get("/health", tags=["å¥åº·æª¢æŸ¥"])
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {
        "status": "healthy",
        "service": "test-model-api",
        "timestamp": datetime.utcnow().isoformat(),
        "models_available": list(MOCK_MODELS.keys())
    }


@app.post("/predict", response_model=PredictionResponse, tags=["é æ¸¬"])
async def predict(request: PredictionRequest) -> PredictionResponse:
    """
    å–®å€‹é æ¸¬ç«¯é»
    
    é€™æ˜¯ä¸»è¦çš„é æ¸¬ APIï¼Œæœƒè¢«ç›£æ§æ””æˆªå™¨ç›£æ§
    """
    start_time = time.perf_counter()
    
    try:
        # é©—è­‰æ¨¡å‹ç‰ˆæœ¬
        if request.model_version not in MOCK_MODELS:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æ´çš„æ¨¡å‹ç‰ˆæœ¬: {request.model_version}"
            )
        
        # é©—è­‰ç‰¹å¾µå‘é‡
        if len(request.features) != 5:
            raise HTTPException(
                status_code=400,
                detail="ç‰¹å¾µå‘é‡å¿…é ˆåŒ…å« 5 å€‹å…ƒç´ "
            )
        
        # åŸ·è¡Œæ¨¡å‹æ¨ç†
        predictions = simulate_model_inference(
            request.features, 
            request.model_version,
            request.metadata
        )
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = (time.perf_counter() - start_time) * 1000
        
        return PredictionResponse(
            predictions=predictions,
            model_version=request.model_version,
            processing_time_ms=processing_time,
            timestamp=datetime.utcnow().isoformat(),
            request_id=f"req_{int(time.time() * 1000)}"
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é æ¸¬å¤±æ•—: {str(e)}")


@app.post("/batch_predict", tags=["é æ¸¬"])
async def batch_predict(request: BatchPredictionRequest) -> Dict[str, Any]:
    """
    æ‰¹é‡é æ¸¬ç«¯é»
    
    ç”¨æ–¼æ¸¬è©¦é«˜ä½µç™¼å’Œå¤§é‡æ•¸æ“šçš„ç›£æ§å ´æ™¯
    """
    start_time = time.perf_counter()
    
    try:
        if not request.samples:
            raise HTTPException(status_code=400, detail="æ¨£æœ¬åˆ—è¡¨ä¸èƒ½ç‚ºç©º")
        
        if len(request.samples) > 100:
            raise HTTPException(status_code=400, detail="æ‰¹æ¬¡å¤§å°ä¸èƒ½è¶…é 100")
        
        # é©—è­‰æ¨¡å‹ç‰ˆæœ¬
        if request.model_version not in MOCK_MODELS:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æ´çš„æ¨¡å‹ç‰ˆæœ¬: {request.model_version}"
            )
        
        # æ‰¹é‡æ¨ç†
        results = []
        for i, features in enumerate(request.samples):
            try:
                # é©—è­‰æ¯å€‹æ¨£æœ¬çš„ç‰¹å¾µæ•¸é‡
                if len(features) != 5:
                    raise ValueError(f"æ¨£æœ¬ {i}: ç‰¹å¾µå‘é‡å¿…é ˆåŒ…å« 5 å€‹å…ƒç´ ï¼Œå¯¦éš›åŒ…å« {len(features)} å€‹")
                
                prediction = simulate_model_inference(features, request.model_version)
                results.append({
                    "sample_id": i,
                    "predictions": prediction,
                    "status": "success"
                })
            except Exception as e:
                results.append({
                    "sample_id": i,
                    "predictions": None,
                    "status": "error",
                    "error": str(e)
                })
        
        processing_time = (time.perf_counter() - start_time) * 1000
        
        return {
            "results": results,
            "total_samples": len(request.samples),
            "successful_predictions": sum(1 for r in results if r["status"] == "success"),
            "model_version": request.model_version,
            "processing_time_ms": processing_time,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡é æ¸¬å¤±æ•—: {str(e)}")


@app.get("/models", response_model=Dict[str, ModelInfo], tags=["æ¨¡å‹ç®¡ç†"])
async def get_models() -> Dict[str, ModelInfo]:
    """ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return MOCK_MODELS


@app.get("/models/{model_version}", response_model=ModelInfo, tags=["æ¨¡å‹ç®¡ç†"])
async def get_model_info(model_version: str) -> ModelInfo:
    """ç²å–ç‰¹å®šæ¨¡å‹ä¿¡æ¯"""
    if model_version not in MOCK_MODELS:
        raise HTTPException(status_code=404, detail=f"æ¨¡å‹ç‰ˆæœ¬ {model_version} ä¸å­˜åœ¨")
    
    return MOCK_MODELS[model_version]


@app.get("/slow_endpoint", tags=["æ¸¬è©¦"])
async def slow_endpoint(delay: float = 2.0):
    """
    æ…¢éŸ¿æ‡‰ç«¯é»ï¼Œç”¨æ–¼æ¸¬è©¦æ€§èƒ½ç›£æ§
    
    Args:
        delay: å»¶é²æ™‚é–“(ç§’)ï¼Œé è¨­ 2 ç§’
    """
    if delay > 10:
        raise HTTPException(status_code=400, detail="å»¶é²æ™‚é–“ä¸èƒ½è¶…é 10 ç§’")
    
    await asyncio.sleep(delay)
    
    return {
        "message": f"å»¶é² {delay} ç§’å¾Œçš„éŸ¿æ‡‰",
        "timestamp": datetime.utcnow().isoformat()
    }


@app.get("/error_endpoint", tags=["æ¸¬è©¦"])
async def error_endpoint(error_type: str = "server_error"):
    """
    éŒ¯èª¤ç«¯é»ï¼Œç”¨æ–¼æ¸¬è©¦éŒ¯èª¤ç›£æ§
    
    Args:
        error_type: éŒ¯èª¤é¡å‹ (client_error, server_error, timeout)
    """
    if error_type == "client_error":
        raise HTTPException(status_code=400, detail="å®¢æˆ¶ç«¯éŒ¯èª¤æ¸¬è©¦")
    elif error_type == "server_error":
        raise HTTPException(status_code=500, detail="ä¼ºæœå™¨éŒ¯èª¤æ¸¬è©¦")
    elif error_type == "timeout":
        await asyncio.sleep(30)  # æ¨¡æ“¬è¶…æ™‚
        return {"message": "ä¸æ‡‰è©²åˆ°é”é€™è£¡"}
    else:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æ´çš„éŒ¯èª¤é¡å‹: {error_type}")


@app.get("/stress_test", tags=["æ¸¬è©¦"])
async def stress_test(requests_count: int = 10):
    """
    å£“åŠ›æ¸¬è©¦ç«¯é»ï¼Œç”¨æ–¼æ¸¬è©¦é«˜ä½µç™¼ç›£æ§
    
    Args:
        requests_count: æ¨¡æ“¬çš„å…§éƒ¨è«‹æ±‚æ•¸é‡
    """
    if requests_count > 100:
        raise HTTPException(status_code=400, detail="è«‹æ±‚æ•¸é‡ä¸èƒ½è¶…é 100")
    
    start_time = time.perf_counter()
    
    # æ¨¡æ“¬è™•ç†å¤šå€‹å…§éƒ¨è«‹æ±‚
    tasks = []
    for i in range(requests_count):
        # éš¨æ©Ÿå»¶é²
        delay = random.uniform(0.01, 0.1)
        tasks.append(asyncio.sleep(delay))
    
    await asyncio.gather(*tasks)
    
    processing_time = (time.perf_counter() - start_time) * 1000
    
    return {
        "processed_requests": requests_count,
        "total_processing_time_ms": processing_time,
        "avg_time_per_request_ms": processing_time / requests_count,
        "timestamp": datetime.utcnow().isoformat()
    }


# ç›£æ§çµ±è¨ˆç«¯é»
@app.get("/monitoring/stats", tags=["ç›£æ§"])
async def get_monitoring_stats():
    """ç²å–ç›£æ§çµ±è¨ˆä¿¡æ¯"""
    health_status = await monitor.get_health_status()
    return health_status


if __name__ == "__main__":
    settings = get_settings()
    
    print("ğŸš€ å•Ÿå‹•æ¸¬è©¦ Model API æœå‹™...")
    print(f"ğŸ“Š ç›£æ§åŠŸèƒ½: å·²å•Ÿç”¨")
    print(f"ğŸ”— API æ–‡æª”: http://localhost:{settings.TEST_MODEL_API_PORT}/docs")
    print(f"ğŸ“ˆ ç›£æ§çµ±è¨ˆ: http://localhost:{settings.TEST_MODEL_API_PORT}/monitoring/stats")
    
    uvicorn.run(
        "test_model_api:app",
        host=settings.API_HOST,
        port=settings.TEST_MODEL_API_PORT,  # ä½¿ç”¨é…ç½®æª”æ¡ˆè¨­å®š
        reload=settings.DEBUG,
        log_level="info"
    ) 